{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jjlim.net/html/b.html\n",
      "http://ak.com/b.html\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "url = \"https://www.jjlim.net/html/a.html\"\n",
    "print(urljoin(url, 'b.html'))\n",
    "print(urljoin(url, 'http://ak.com/b.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze_html= https://docs.python.org/3.6/library/asyncio-task.html\n",
      "download= https://docs.python.org/3.6/library/asyncio-protocol.html\n",
      "analyze_html= https://docs.python.org/3.6/library/asyncio-protocol.html\n",
      "download= https://docs.python.org/3.6/library/asyncio-stream.html\n",
      "analyze_html= https://docs.python.org/3.6/library/asyncio-stream.html\n",
      "download= https://docs.python.org/3.6/library/asyncio-subprocess.html\n",
      "analyze_html= https://docs.python.org/3.6/library/asyncio-subprocess.html\n",
      "download= https://docs.python.org/3.6/library/asyncio-sync.html\n",
      "analyze_html= https://docs.python.org/3.6/library/asyncio-sync.html\n",
      "download= https://docs.python.org/3.6/library/asyncio-queue.html\n",
      "analyze_html= https://docs.python.org/3.6/library/asyncio-queue.html\n",
      "download= https://docs.python.org/3.6/library/asyncio-dev.html\n",
      "analyze_html= https://docs.python.org/3.6/library/asyncio-dev.html\n",
      "download= https://docs.python.org/3.6/library/asyncore.html\n",
      "analyze_html= https://docs.python.org/3.6/library/asyncore.html\n",
      "download= https://docs.python.org/3.6/library/asynchat.html\n",
      "analyze_html= https://docs.python.org/3.6/library/asynchat.html\n",
      "download= https://docs.python.org/3.6/library/signal.html\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from urllib.request import urlretrieve\n",
    "from os import makedirs\n",
    "import os.path, time, re\n",
    "\n",
    "url = \"https://docs.python.org/3.6/library/\"\n",
    "\n",
    "proc_files = {}\n",
    "\n",
    "def enum_links(html, base):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup.select(\"link[rel='stylesheet']\")\n",
    "    links += soup.select('a[href]')\n",
    "    result = []\n",
    "    \n",
    "    for a in links:\n",
    "        href = a.attrs['href']\n",
    "        url = urljoin(base, href) # 절대경로로 바꿔주기 위해서 처음 url에다 href에 있는 뒤에 주소를 합침\n",
    "        result.append(url)\n",
    "        \n",
    "    return result\n",
    "\n",
    "def download_file(url):\n",
    "    test_url = urlparse(url)\n",
    "    savepath = './' + test_url.netloc + test_url.path\n",
    "    \n",
    "    if re.search(r'/$', savepath):\n",
    "        savepath += 'index.html'\n",
    "    # savepath: ./docs.python.org/3.6/library/index.html        \n",
    "\n",
    "    savedir = os.path.dirname(savepath)\n",
    "    # savedir: ./docs.python.org/3.6/library \n",
    "    \n",
    "    # savepath 경로와 파일이 이미 있을경우 다른 작업 없이 savepath를 리턴\n",
    "    if os.path.exists(savepath):\n",
    "        return savepath\n",
    "    \n",
    "    # 다운로드할때 폴더(savedir)이름이 이미 생성 되었는지 확인. 없으면 만들기.\n",
    "    if not os.path.exists(savedir):\n",
    "        print('mkdir=', savedir)\n",
    "        makedirs(savedir)\n",
    "    \n",
    "    try:\n",
    "        # 다운로드 됐을경우 다운로드 완료를 알리고, savapath 경로와 파일 이름으로 다운로드 파일 생성\n",
    "        # savepath를 리턴\n",
    "        print('download=', url)\n",
    "        urlretrieve(url, savepath)\n",
    "        time.sleep(1)\n",
    "        return savepath\n",
    "    \n",
    "    # 오류 났을경우 다운로드 실패라고 표시해라\n",
    "    except:\n",
    "        print('download failed: ', url)\n",
    "        return None\n",
    "\n",
    "def analyze_html(url, root_url):\n",
    "    savepath = download_file(url)\n",
    "    \n",
    "    if savepath is None:\n",
    "        return\n",
    "    \n",
    "    # 이미 분석한(proc_files에 있으면) 파일이면 함수실행 나가기\n",
    "    if savepath in proc_files:\n",
    "        return\n",
    "    \n",
    "    # 분석하지 않은 savepath 이므로 딕셔너리로 {경로:True}로 저장\n",
    "    proc_files[savepath] = True\n",
    "    print('analyze_html=', url)\n",
    "    \n",
    "    # savepath의 index.html을 읽기\n",
    "    with open(savepath, encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        links = enum_links(html, url) # css 파일이나 a href에 있는 경로를 절대 경로로 만든 리스트\n",
    "        \n",
    "        \n",
    "        for link_url in links:\n",
    "            if link_url.find(root_url) != 0:\n",
    "                if not re.search(r'.css$', link_url):\n",
    "                    continue\n",
    "            \n",
    "            # html이나 htm인 확장자면 재귀 함수로 분석을 다시 시작\n",
    "            if re.search(r'.(html|html)$', link_url):\n",
    "                analyze_html(link_url, root_url)\n",
    "                continue\n",
    "            \n",
    "            # 다운로드 실행\n",
    "            download_file(link_url)\n",
    "\n",
    "#실행\n",
    "analyze_html(url, url)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as ureq\n",
    "import datetime\n",
    "\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "html = ureq.urlopen(url)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "price = soup.select_one('div.head_info > span.value').string\n",
    "change = soup.select_one('div.head_info > span.change').string\n",
    "blind = soup.select_one('div.head_info > span.blind').string\n",
    "exchange = datetime.date.today()\n",
    "folder = './exrate/'\n",
    "file_n = folder + exchange.strftime('%Y-%m-%d') + '.txt'\n",
    "\n",
    "with open(file_n, 'w', encoding='utf-8') as g:\n",
    "    g.write('환율 현재 가격은 {}원이고 변동 가격은 {}원으로 {} 입니다.'.format(price,change,blind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
