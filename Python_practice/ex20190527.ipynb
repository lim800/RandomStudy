{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빅데이터 플랫폼 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>로빈훗</p>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "html = \"\"\"\n",
    "<h1>aaaa</h1>\n",
    "<body>\n",
    "<h1>홍길동</h1>\n",
    "<p>전우치</P>\n",
    "<p>로빈훗</P>\n",
    "<p>소머즈</p>\n",
    "</body>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "h11 = soup.body.p.next_sibling.next_sibling\n",
    "print(h11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "객체지향 언어는\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<p>언어이므로 반복만이 실력이 향상된다.</p>\n",
    "<h1 id=\"title\">객체지향 언어는</h1>\n",
    "<p>클래스 기반의 언어와 프로토타입 기반의 언어가 있다.</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "title = soup.find('h1')\n",
    "print(title.string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"http://so.co.kr/spring\">spring</a>]\n",
      "http://so.co.kr/spring\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html2 = \"\"\"\n",
    "<ul>\n",
    "<li><a href=\"https://so.net/java\">java</a></li>\n",
    "<li><a href=\"https://so.com/python\">python</a></li>\n",
    "<li><a href=\"http://so.co.kr/spring\">spring</a></li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html2, 'html.parser')\n",
    "li = soup.find_all(href = re.compile(r'^http://'))\n",
    "# li = soup.find_all('a')\n",
    "print(li)\n",
    "for i in li:\n",
    "    print(i.attrs['href'])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul>\n",
      " <li>\n",
      "  <a href=\"https://so.net/java\">\n",
      "   java\n",
      "  </a>\n",
      " </li>\n",
      " <li>\n",
      "  <a href=\"https://so.com/python\">\n",
      "   python\n",
      "  </a>\n",
      " </li>\n",
      " <li>\n",
      "  <a href=\"http://so.co.kr/spring\">\n",
      "   spring\n",
      "  </a>\n",
      " </li>\n",
      "</ul>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html2 = \"\"\"\n",
    "<ul>\n",
    "<li><a href=\"https://so.net/java\">java</a></li>\n",
    "<li><a href=\"https://so.com/python\">python</a></li>\n",
    "<li><a href=\"http://so.co.kr/spring\">spring</a></li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html2, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attrs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "True\n",
      "https://www.naver.com\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<p><a href=\"https://www.naver.com\">naver</a></p> </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html, 'html.parser') \n",
    "a = soup.p.a\n",
    "print(type(a.attrs))\n",
    "href = 'href' in a.attrs\n",
    "print(href) \n",
    "print(a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빅데이터의 요소\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<div id=\"bigdata\"> \n",
    "<h3>빅데이터의 요소</h3>\n",
    "<ul> \n",
    "<li>크기(Volume)</li> \n",
    "<li>다양성(Variety)</li> \n",
    "<li>속도(Velocity)</li> \n",
    "<li>정확성(Veracity)</li> \n",
    "<li>가치(Value)</li>\n",
    "</ul> \n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "h3 = soup.select_one('div#bigdata > h3').string \n",
    "print(h3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h3>빅데이터의 요소1</h3>, <h3>빅데이터의 요소2</h3>, <h3>빅데이터의 요소3</h3>]\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<div id=\"bigdata\"> \n",
    "<h3>빅데이터의 요소1</h3>\n",
    "<ul> \n",
    "<li>크기(Volume)</li> \n",
    "<li>다양성(Variety)</li> \n",
    "<li>속도(Velocity)</li> \n",
    "<li>정확성(Veracity)</li> \n",
    "<li>가치(Value)</li>\n",
    "</ul> \n",
    "</div>\n",
    "<div id=\"bigdata\"> \n",
    "<h3>빅데이터의 요소2</h3>\n",
    "<ul> \n",
    "<li>크기(Volume)</li> \n",
    "<li>다양성(Variety)</li> \n",
    "<li>속도(Velocity)</li> \n",
    "<li>정확성(Veracity)</li> \n",
    "<li>가치(Value)</li>\n",
    "</ul> \n",
    "</div>\n",
    "<div id=\"bigdata\"> \n",
    "<h3>빅데이터의 요소3</h3>\n",
    "<ul> \n",
    "<li>크기(Volume)</li> \n",
    "<li>다양성(Variety)</li> \n",
    "<li>속도(Velocity)</li> \n",
    "<li>정확성(Veracity)</li> \n",
    "<li>가치(Value)</li>\n",
    "</ul> \n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "h3 = soup.select('div#bigdata > h3')\n",
    "print(h3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li id=\"html\">HTML</li>\n",
      "<li class=\"script\">Java Script</li>\n",
      "<li id=\"html\">HTML</li>\n",
      "<li class=\"java\">Java</li>\n",
      "<li id=\"html\">HTML</li>\n",
      "<li class=\"spring\">Spring Framework</li>\n",
      "<li id=\"html\">HTML</li>\n",
      "<li class=\"python\">Python</li>\n",
      "<li id=\"html\">HTML</li>\n",
      "<li class=\"python\">Python</li>\n",
      "<li id=\"html\">HTML</li>\n",
      "<li class=\"python\">Python</li>\n",
      "<li class=\"spring\">Spring Framework</li>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<ul id=\"language\">\n",
    "<li id=\"html\">HTML</li>\n",
    "<li class=\"script\">Java Script</li>\n",
    "<li class=\"java\">Java</li>\n",
    "<li class=\"spring\">Spring Framework</li> \n",
    "<li class=\"python\">Python</li>\n",
    "</ul> \n",
    "</body> \n",
    "</html> \n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html, 'html.parser') \n",
    "print(soup.select_one('#html')) #id로 찾기\n",
    "print(soup.select_one('.script')) #class로 찾기\n",
    "print(soup.select_one('li#html')) #요소 + id로 찾기\n",
    "print(soup.select_one('li.java')) #요소 + class로 찾기\n",
    "print(soup.select_one('#language #html')) #공백을 줘서 아이디 language의 자식 전체 중 아이디 html로 찾기\n",
    "print(soup.select_one('#language .spring')) #공백을 줘서 아이디 language의 자식 전체 중 클래스 spring으로 찾기\n",
    "print(soup.select_one('ul > li#html')) \n",
    "print(soup.select_one('ul > li.python')) \n",
    "print(soup.select_one('ul#language > li#html')) \n",
    "print(soup.select_one('ul#language > li.python')) \n",
    "print(soup.select_one(\"li[id='html']\")) \n",
    "print(soup.select_one(\"li[class='python']\")) \n",
    "print(soup.select_one('li:nth-of-type(4)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li class=\"java\">Spring Framework</li>\n",
      "<li class=\"java\">Java</li>\n",
      "<li class=\"java\">Spring Framework</li>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<ul id=\"language\">\n",
    "<li id=\"html\">HTML</li>\n",
    "<li class=\"script\">Java Script</li>\n",
    "<li class=\"java\">Java</li>\n",
    "<li class=\"java\">Spring Framework</li> \n",
    "<li class=\"python\">Python</li>\n",
    "</ul> \n",
    "<body> \n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html, 'html.parser') \n",
    "print(soup.select('li')[3]) \n",
    "print(soup.select(\"#language > li[class='java']\")[0]) \n",
    "print(soup.select(\"#language > li.java\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘과 바람과 별과 시\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as req\n",
    "url = 'https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC'\n",
    "html = req.urlopen(url)\n",
    "# print(url)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# print(soup)\n",
    "list_one = soup.select_one(\"#mw-content-text > div > ul > li > b > a\")\n",
    "\n",
    "print(list_one.string)\n",
    "\n",
    "# for list_all in list_one:\n",
    "#     print('-', list_all.string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students walk out in global climate strike\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.bbc.com/news/science_and_environment'\n",
    "html = req.urlopen(url)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "list_one = soup.select_one(\"#topos-component > div.no-mpu > div > div > div > div.gel-layout__item.gel-1\\/1.gel-3\\/5\\@xxl.gs-u-display-none\\@xl.gs-u-display-block\\@xxl > div > div > div > div.gs-c-promo-body.gs-u-mt\\@xxs.gs-u-mt\\@m.gs-c-promo-body--flex.gs-u-mt\\@xs.gs-u-mt0\\@xs.gs-u-mt\\@m.gel-1\\/2\\@xs.gel-1\\/1\\@s > div > a > h3\")\n",
    "\n",
    "print(list_one.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Students walk out in global climate strike\n",
      "- 'Sabotaged' tanker in Gulf of Oman leaked oil\n",
      "- Three more die on Everest amid overcrowding\n",
      "- The man who made Einstein world-famous\n",
      "- SpaceX puts up 60 internet satellites\n",
      "- 'How can I help fight climate change?'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as req\n",
    "url = 'https://www.bbc.com/news/science_and_environment'\n",
    "html = req.urlopen(url)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# print(soup)\n",
    "\n",
    "lists = soup.select(\"#topos-component > div.no-mpu > div > div > div > div.gel-layout__item.gel-1\\/1.gel-3\\/5\\@xxl.gs-u-display-none\\@xl.gs-u-display-block\\@xxl > div > div > div > div.gs-c-promo-body.gs-u-mt\\@xxs.gs-u-mt\\@m.gs-c-promo-body--flex.gs-u-mt\\@xs.gs-u-mt0\\@xs.gs-u-mt\\@m.gel-1\\/2\\@xs.gel-1\\/1\\@s > div > a > h3\")\n",
    "\n",
    "# print(lists.string)\n",
    "\n",
    "for i in lists:\n",
    "    print('-', i.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국USD 환전고시환율의 현재 가격은 1,185.00원 입니다.\n",
      "미국USD 환전고시환율의 변동 가격은  3.00원 하락 중 입니다.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as req\n",
    "url = 'https://finance.naver.com/marketindex/?tabSel=exchange#tab_section'\n",
    "html = req.urlopen(url)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "price = soup.select_one('#exchangeList > li.on > a.head.usd > div > span.value').string\n",
    "\n",
    "change = soup.select_one('#exchangeList > li.on > a.head.usd > div > span.change').string\n",
    "\n",
    "updown = soup.select_one('#exchangeList > li.on > a.head.usd > div > span.blind').string\n",
    "\n",
    "\n",
    "print('미국USD 환전고시환율의 현재 가격은 {}원 입니다.'.format(price))\n",
    "print('미국USD 환전고시환율의 변동 가격은 {}원 {} 중 입니다.'.format(change, updown))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지역: 강원 | 상태: 좋음\n",
      "지역: 서울 | 상태: 좋음\n",
      "지역: 충남 | 상태: 좋음\n",
      "지역: 충북 | 상태: 좋음\n",
      "지역: 대전 | 상태: 좋음\n",
      "지역: 경북 | 상태: 좋음\n",
      "지역: 전남 | 상태: 좋음\n",
      "지역: 인천 | 상태: 좋음\n",
      "지역: 부산 | 상태: 좋음\n",
      "지역: 대구 | 상태: 좋음\n",
      "지역: 제주 | 상태: 좋음\n",
      "지역: 전북 | 상태: 좋음\n",
      "지역: 울산 | 상태: 좋음\n",
      "지역: 경남 | 상태: 좋음\n",
      "지역: 광주 | 상태: 좋음\n",
      "지역: 세종 | 상태: 좋음\n",
      "지역: 경기 | 상태: 좋음\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as req\n",
    "url = 'https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=%EB%AF%B8%EC%84%B8%EB%A8%BC%EC%A7%80'\n",
    "html = req.urlopen(url)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "loc = soup.select('#main_pack div.tb_scroll > table > tbody > tr > th')\n",
    "status = soup.select('#main_pack div.tb_scroll > table > tbody > tr > td > span.lv1')\n",
    "aaa = dict(zip(loc,status))\n",
    "# print(aaa)\n",
    "for i, j in aaa.items():\n",
    "    print('지역: {} | 상태: {}'.format(i.string, j.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[외환마감]상승 분위기 꺾였나..환율, 6일 연속 내려 1184.50원\n",
      "[초점]\"무역분쟁 불확실성 잔존…배당주·IT성장주 관심\"\n",
      "무역갈등에 경제지표까지 '깜깜'…\"소나기 피할 종목을 찾아라\"\n",
      "[굿모닝 증시]한달 뒤 G20 바라보는 증권시장\n",
      "\"금리인하 검토 안한다\"는 한은, 변화 조짐 나타날까\n",
      "[e슬기로운 투자생활]무역분쟁 대응책 요구하기 시작한 투자자들\n",
      "주요뉴스 더보기\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://finance.naver.com/\"\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "news = soup.select(\"div.news_area a\")\n",
    "\n",
    "for i in news:\n",
    "    print(i.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "session_use = requests.session()\n",
    "login_info = {\"p\":\"3119\",\"cb\":\"58232985154\"}\n",
    "\n",
    "url_login = \"https://dis.as.criteo.com/dis/dis.aspx?p=3119&cb=58232985154&ref=&sc_r=1440x900&sc_d=24\"\n",
    "response_login = session_use.get(url_login, params=login_info)\n",
    "print(response_login)\n",
    "url_mypage = \"https://my.coupang.com/purchase/list\"\n",
    "response_mypage = session_use.get(url_mypage)\n",
    "html = response_mypage.text\n",
    "print(html)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
